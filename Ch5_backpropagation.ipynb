{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f8951ba-ea8b-4982-8fd5-acb2c99ea66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27235e31-622e-4e1c-b4f8-b5238a58ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw text data\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "# Construct the vocabulary\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos) # 27\n",
    "\n",
    "# Hyperparameters\n",
    "block_size = 3 # Context length: predict the 4th character from 3 previous\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # Slide the window\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "# Split the dataset: 80% Train, 10% Dev, 10% Test\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b372981-6eb3-44dc-ba92-34a5ab1b1c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10  # Embedding dimensionality\n",
    "n_hidden = 64 # Hidden layer neurons\n",
    "\n",
    "# 1. Embedding Matrix\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# 2. Layer 1 Weights (Kaiming Init)\n",
    "# We multiply by (5/3) / sqrt(fan_in) where fan_in is n_embd * block_size (30)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "# Layer 1 Bias (scaled down to reduce initial impact)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "\n",
    "# 3. Layer 2 Weights (Output Projection)\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# 4. Batch Normalization Parameters\n",
    "# Scale (gamma) initialized to 1.0 + small noise (not 0!)\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "# Shift (beta) initialized to 0 + small noise\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Collect all parameters\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "print(f\"Total Parameters: {sum(p.nelement() for p in parameters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aab21fd4-27a5-4d5b-b14b-1f2e3d4c0c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.346653461456299\n"
     ]
    }
   ],
   "source": [
    "# Construct a minibatch of size 32\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "# --- Layer 1: Embedding ---\n",
    "emb = C[Xb] # (32, 3, 10)\n",
    "embcat = emb.view(-1, block_size * n_embd) # Flatten to (32, 30)\n",
    "\n",
    "# --- Layer 2: Linear Projection ---\n",
    "# Matrix multiplication: (32, 30) @ (30, 64) + (64,) -> (32, 64)\n",
    "hprebn = embcat @ W1 + b1 \n",
    "\n",
    "# --- Layer 3: Batch Normalization (Decomposed) ---\n",
    "# 1. Calculate Mean across batch (dim 0)\n",
    "bnmeani = 1/n * hprebn.sum(0, keepdim=True)\n",
    "# 2. Calculate Centered Data\n",
    "bndiff = hprebn - bnmeani\n",
    "# 3. Calculate Squared Differences\n",
    "bndiff2 = bndiff**2\n",
    "# 4. Calculate Variance (Bessel's Correction applied: n-1)\n",
    "bnvar = 1/(n-1) * (bndiff2).sum(0, keepdim=True)\n",
    "# 5. Calculate Inverse Standard Deviation (adding epsilon for stability)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# 6. Normalize\n",
    "bnraw = bndiff * bnvar_inv\n",
    "# 7. Scale and Shift (Gamma and Beta)\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# --- Layer 4: Non-linearity ---\n",
    "h = torch.tanh(hpreact) # (32, 64)\n",
    "\n",
    "# --- Layer 5: Linear Projection to Logits ---\n",
    "logits = h @ W2 + b2 # (32, 64) @ (64, 27) + (27,) -> (32, 27)\n",
    "\n",
    "# --- Layer 6: Cross Entropy Loss (Decomposed) ---\n",
    "# 1. Numerical Stability (Max trick)\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "# 2. Exponentiate\n",
    "counts = norm_logits.exp()\n",
    "# 3. Sum counts for normalization\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "# 4. Invert sum\n",
    "counts_sum_inv = counts_sum**-1\n",
    "# 5. Probabilities (Softmax)\n",
    "probs = counts * counts_sum_inv\n",
    "# 6. Log Probabilities\n",
    "logprobs = probs.log()\n",
    "# 7. Negative Log Likelihood Loss\n",
    "# Index into the rows (range(n)) at the columns specified by targets (Yb)\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e19ec5-5fe3-4d96-a4ef-bffc5e7717af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset gradients\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "# We must explicitly call retain_grad() on intermediate tensors\n",
    "# because PyTorch normally discards non-leaf gradients to save memory.\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, \n",
    "          norm_logits, logits, h, hpreact, bnraw, bnvar_inv, \n",
    "          bnvar, bndiff2, bndiff, bnmeani, hprebn, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71b035-e450-4abf-9a86-a9d0ee53e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    if t.grad is None:\n",
    "        print(f'{s:15s} | exact: False | approximate: False | maxdiff: inf (grad is None)')\n",
    "        return\n",
    "    # Ensure shapes match\n",
    "    if dt.shape != t.grad.shape:\n",
    "        print(f'{s:15s} | exact: False | approximate: False | maxdiff: inf (shape mismatch: {dt.shape} vs {t.grad.shape})')\n",
    "        return\n",
    "    # Compare tensors\n",
    "    diff = (dt - t.grad)\n",
    "    ex = torch.all(diff == 0).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = diff.abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "761ee544-1a53-46e1-9975-9887329f9510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc3c80b-3623-44c7-b208-dabed3008ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c44b5434-fb2e-494b-b470-e937c17af178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ec8909d-bac6-4dcf-a8a6-ad541098b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70b9a0b7-5f22-4a18-93bd-f413955a7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts = counts_sum_inv * dprobs # Contribution from probs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum # Contribution from sum\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "832efd72-3f9d-4b0e-ac90-9e11e3e61966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dnorm_logits = counts * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1587284b-2fd7-49f7-bbcd-e5dd8588bda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits = dnorm_logits.clone() # Path 1\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # Path 2\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5cd79dc-40e8-4051-80ff-d5ef729179d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "032fea75-d982-49b1-b9c4-4efa4fa2db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4511824-8f6e-4457-a097-6c00fbb3b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b43c6461-fae2-4881-86c2-75d0c98ce101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw # Only the first contribution\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14dae013-5063-47ae-b2d7-5a5dc92755e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
     ]
    }
   ],
   "source": [
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e81ecf48-8cf7-42f0-947f-e262aaf5d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n"
     ]
    }
   ],
   "source": [
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37044924-f1ed-43a4-b47b-31aa59d07613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "dbndiff += (2 * bndiff) * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bfdaa1c-944b-4795-836e-49735c355807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26770/614943589.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  ex = torch.all(dt == t.grad).item()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dbnmeani \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mdbndiff)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m dhprebn \u001b[38;5;241m=\u001b[39m dbndiff\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;66;03m# Path 1 contribution\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcmp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbnmeani\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbnmeani\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbnmeani\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mcmp\u001b[0;34m(s, dt, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcmp\u001b[39m(s, dt, t):\n\u001b[0;32m----> 2\u001b[0m     ex \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      3\u001b[0m     app \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mallclose(dt, t\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      4\u001b[0m     maxdiff \u001b[38;5;241m=\u001b[39m (dt \u001b[38;5;241m-\u001b[39m t\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "dbnmeani = (-dbndiff).sum(0, keepdim=True)\n",
    "dhprebn = dbndiff.clone() # Path 1 contribution\n",
    "cmp('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91beda5e-9714-47c3-a52f-2373c46c990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "dhprebn += (1.0/n) * (torch.ones_like(hprebn) * dbnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "effefb78-1a04-4ea9-abf4-f7793ea95013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1              | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "313b0e13-b2fe-4cfb-95f6-3f59a7e07d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n"
     ]
    }
   ],
   "source": [
    "demb = dembcat.view(emb.shape[0], emb.shape[1], emb.shape[2])\n",
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9ab672d-b8e5-47fa-bc54-9fa042899080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):   # Iterate over batch\n",
    "    for j in range(Xb.shape[1]): # Iterate over context position\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j] # Accumulate gradient\n",
    "\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0b5432a-484f-406f-9403-16dc93b61c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_fast     | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "# Fused Softmax gradient\n",
    "# The gradient of cross-entropy loss w.r.t. logits is: (probs - one_hot(Yb)) / n\n",
    "probs_fast = F.softmax(logits, dim=1)\n",
    "dlogits_fast = probs_fast.clone()\n",
    "# Subtract 1 from the correct class positions\n",
    "dlogits_fast[range(n), Yb] -= 1.0\n",
    "# Divide by batch size\n",
    "dlogits_fast /= n\n",
    "\n",
    "cmp('logits_fast', dlogits_fast, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2742cc-91a5-4831-a26c-e5b442402325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn_fast     | exact: False | approximate: False | maxdiff: 3.117695450782776e-05\n"
     ]
    }
   ],
   "source": [
    "# Fused Batch Norm gradient\n",
    "# This combines all the paths: through bnraw, through mean, and through variance\n",
    "bn_var_inv = (bnvar + 1e-5)**-0.5\n",
    "aux = (dlogits @ W2.T) * (1.0 - h**2) # This is dhpreact\n",
    "# Multiply by bngain to get dbnraw (from Cell 15: dbnraw = bngain * dhpreact)\n",
    "dbnraw_fast = bngain * aux\n",
    "# The fused formula accounts for all contributions\n",
    "# Note: variance uses (n-1) for Bessel's correction, so we need to account for that\n",
    "dhprebn_fast = bn_var_inv * (\n",
    "    dbnraw_fast \n",
    "    - dbnraw_fast.sum(0, keepdim=True) / n  # Mean contribution\n",
    "    - bnraw * (dbnraw_fast * bnraw).sum(0, keepdim=True) / (n - 1)  # Variance contribution (uses n-1)\n",
    ")\n",
    "\n",
    "cmp('hprebn_fast', dhprebn_fast, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cb2f4-361d-4c46-a217-2dda7756bf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f724a3-2622-45c9-8f82-8e23e306fd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
